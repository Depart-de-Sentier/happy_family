{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e42e9-dede-4505-a3dc-480e23b307a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw_processing.constants import DEFAULT_LICENSES\n",
    "from bw_processing.filesystem import clean_datapackage_name, safe_filename\n",
    "from bw_processing.utils import check_name\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847867c-7a9f-4d23-9b11-e926c5a2ceeb",
   "metadata": {},
   "source": [
    "Had some trouble here as I didn't realize that `indicators` originally comes with the same length as `cfs`, so the joins were in effect cross products. One could in theory join these two `DataFrames` based on the indices, but I feel more comfortable using `drop_duplicates` and actually joining on the data attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9cc05-fcb8-4726-bf0b-471e7dfee1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_formatted_dataframe(excel_fp, separator=\"|\"):\n",
    "    cfs = pd.read_excel(\n",
    "        excel_fp, \n",
    "        sheet_name=\"CFs\"\n",
    "    ).rename(columns={'CF': 'Characterization factor', 'Name': 'Flowable'})\n",
    "    indicators = pd.read_excel(\n",
    "        excel_fp,\n",
    "        sheet_name=\"Indicators\"\n",
    "    ).drop_duplicates().rename(columns={'Unit': 'Indicator unit'})\n",
    "    cfs_merged = pd.merge(cfs, indicators, how='left', on=['Method', 'Category', 'Indicator'])\n",
    "    assert len(cfs_merged) == len(cfs)\n",
    "    \n",
    "    cfs_merged['Context'] = cfs.apply(lambda row: row['Compartment'] + separator + row['Subcompartment'], axis=1)\n",
    "    cfs_merged['Indicator'] = cfs.apply(lambda row: row['Category'] + separator + row['Indicator'], axis=1)\n",
    "    cfs_merged.drop(columns=['Compartment', 'Subcompartment', 'Category'], inplace=True)\n",
    "    return cfs_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22942e43-65b1-4ebe-8702-26a8f32d57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD_METADATA = json.load(open(\"methods.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37567a25-a5e8-4ee8-b73c-8698658ad4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATOR_MAPPING = {\n",
    "    (row['method'], row['indicator']): row['uuid'] \n",
    "    for row in json.load(open(\"indicators.json\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6cfeb-98e7-4f83-bf6b-5b23144636f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_method_metadata(df, method_metadata):\n",
    "    new_data = {\n",
    "        key: {\n",
    "            \"version\": \"1.0\",\n",
    "            \"description\": \"\",\n",
    "            \"url\": \"\",\n",
    "            \"uuid\": uuid.uuid4().hex,\n",
    "        } for key in set(df['Method']).difference(set(method_metadata))\n",
    "    }\n",
    "    if new_data:\n",
    "        method_metadata.update(new_data)\n",
    "        with open(\"methods.json\", \"w\") as f:\n",
    "            json.dump(\n",
    "                {key: method_metadata[key] for key in sorted(method_metadata)}, \n",
    "                f, \n",
    "                ensure_ascii=False, \n",
    "                indent=2\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f5901-24c6-497f-965f-7bbc7770f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_indicator_metadata(df, indicator_metadata):\n",
    "    keys = {\n",
    "        (tpl.Method, tpl.Indicator)\n",
    "        for tpl in df[['Method', 'Indicator']].drop_duplicates(ignore_index=True).itertuples()\n",
    "    }\n",
    "    new_data = {\n",
    "        key: uuid.uuid4().hex\n",
    "        for key in keys \n",
    "        if key not in indicator_metadata\n",
    "    }\n",
    "    if new_data:\n",
    "        indicator_metadata.update(new_data)\n",
    "        with open(\"indicators.json\", \"w\") as f:\n",
    "            json.dump(\n",
    "                sorted(\n",
    "                    [\n",
    "                        {\n",
    "                            'method': key[0],\n",
    "                            'indicator': key[1],\n",
    "                            'uuid': value\n",
    "                        } for key, value in indicator_metadata.items()\n",
    "                    ], key=lambda x: (x['method'], x['indicator'])\n",
    "                ),\n",
    "                f, \n",
    "                ensure_ascii=False, \n",
    "                indent=2\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56fd12-9b10-475e-a769-0a7aac1f2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_dataframe(version):\n",
    "    fp = Path(f\"/Users/chrismutel/Sync/Documents/LCA/Ecoinvent/{version}/LCIA/LCIA Implementation {version}.xlsx\")\n",
    "    if not fp.exists():\n",
    "        fp = Path(f\"/Users/chrismutel/Sync/Documents/LCA/Ecoinvent/{version}/LCIA/LCIA Implementation v{version}.xlsx\")\n",
    "    if not fp.exists():\n",
    "        fp = Path(f\"/Users/chrismutel/Sync/Documents/LCA/Ecoinvent/{version}/LCIA/LCIA_Implementation_{version}.xlsx\")\n",
    "    if not fp.exists():\n",
    "        raise ValueError(f\"File not found: {fp}\")\n",
    "    \n",
    "    df = load_formatted_dataframe(fp)\n",
    "    flows = pd.read_csv(Path.cwd().parent / \"Elementary flow mapping\" / \"outputs\" / f\"ecoinvent-{version}\" / f\"ecoinvent-{version}.csv\")    \n",
    "\n",
    "    add_to_method_metadata(df, METHOD_METADATA)\n",
    "    add_to_indicator_metadata(df, INDICATOR_MAPPING)\n",
    "    \n",
    "    df['Method UUID'] = df.apply(lambda row: METHOD_METADATA[row['Method']]['uuid'], axis=1)\n",
    "    df['Indicator UUID'] = df.apply(lambda row: INDICATOR_MAPPING[(row['Method'], row['Indicator'])], axis=1)   \n",
    "    df = pd.merge(df, flows, how='left', on=['Flowable', 'Context'])\n",
    "\n",
    "    missing_mask = df['Flow UUID'].isnull()\n",
    "    if sum(missing_mask):\n",
    "        print(\"Dropping {} flows not mapped in elementary flow list\".format(sum(missing_mask)))\n",
    "        df = df[~missing_mask]\n",
    "    \n",
    "    df.drop(columns=['Formula', 'Synonyms', 'Class', 'ExternalReference', 'Preferred', 'AltUnit', 'Second CAS'], inplace=True)\n",
    "    return df[[\n",
    "        'Method', 'Method UUID', 'Indicator', 'Indicator UUID', \n",
    "        'Indicator unit', 'Flowable', 'Flow UUID', 'Context', \n",
    "        'Unit', 'CAS No', 'Characterization factor'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5797c8-2be7-454f-b471-f1c6ba961f11",
   "metadata": {},
   "source": [
    "Split into separate dataframes for each method family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158e3a1-3c71-4c27-80a3-b833f4713ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    return s.replace(\" \", \"_\").replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe52ae9-a1c1-427b-9688-2889e0855bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resources_and_metadata(df):\n",
    "    all_methods = sorted(df['Method'].unique())\n",
    "\n",
    "    metadata, resources = [], []\n",
    "\n",
    "    for method in all_methods:\n",
    "        assert method in METHOD_METADATA\n",
    "        filename = safe_filename(clean(method), add_hash=False)\n",
    "\n",
    "        # TODO: Could specify a specific resource profile just for LCIA data \n",
    "        # to avoid repeating columns, and for data validation\n",
    "\n",
    "        metadata.append({\n",
    "            \"path\": f\"{filename}.csv\",\n",
    "            \"profile\": \"tabular-data-resource\",\n",
    "            \"mediatype\": \"text/csv\",\n",
    "            \"separator\": \"|\",\n",
    "            \"schema\": {\n",
    "                \"fields\": [\n",
    "                    {'name': 'Method', 'type': 'string'},\n",
    "                    {'name': 'Method UUID', 'type': 'string'},\n",
    "                    {'name': 'Indicator', 'type': 'string', 'separated': True},\n",
    "                    {'name': 'Indicator UUID', 'type': 'string'},\n",
    "                    {'name': 'Indicator unit', 'type': 'string'},\n",
    "                    {'name': 'Flowable', 'type': 'string'},\n",
    "                    {'name': 'Flow UUID', 'type': 'string'},\n",
    "                    {'name': 'Context', 'type': 'string', 'separated': True},\n",
    "                    {'name': 'Unit', 'type': 'string'},\n",
    "                    {'name': 'CAS No', 'type': 'string'},\n",
    "                    {'name': 'Characterization factor', 'type': 'number'},\n",
    "                ],\n",
    "            },\n",
    "        })\n",
    "\n",
    "        resources.append(df[df.Method == method])    \n",
    "        \n",
    "    return resources, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eccaa6-ac79-4551-9b9d-fb3feca27bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECOINVENT_EULA_LICENSE = {\n",
    "    \"name\": \"ecoinvent-eula-2022.05.01\",\n",
    "    \"path\": \"https://ecoinvent.org/wp-content/uploads/2022/04/ecoinvent_new-db-eula_01_04_2022.pdf\",\n",
    "    \"title\": \"ecoinvent End User Licence Agreement effect 2022.05.01\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c81da2-c77d-4b57-9a2d-c95ff8256271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datapackage(\n",
    "    dirpath: Path,\n",
    "    resources: list,\n",
    "    resources_metadata: list,\n",
    "    name: str,\n",
    "    author: str,\n",
    "    description: str,\n",
    "    elementary_flow_lists: Optional[list] = None,\n",
    "    version: Optional[str] = None,\n",
    "    id_: Optional[str] = None,\n",
    "    licenses: Optional[list] = None,\n",
    "):\n",
    "    dirpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    name = clean_datapackage_name(name)\n",
    "    check_name(name)\n",
    "\n",
    "    metadata = {\n",
    "        \"profile\": \"tabular-data-package\",  # https://dataprotocols.org/tabular-data-package/\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"id\": id_ or uuid.uuid4().hex,\n",
    "        \"licenses\": licenses or DEFAULT_LICENSES,\n",
    "        \"resources\": resources_metadata,\n",
    "        \"created\": datetime.datetime.utcnow().isoformat(\"T\") + \"Z\",\n",
    "    }\n",
    "\n",
    "    json.dump(metadata, open(dirpath / \"metadata.json\", \"w\"), indent=2, ensure_ascii=False)\n",
    "    \n",
    "    for df, meta in zip(resources, resources_metadata):\n",
    "        df.to_csv(dirpath / meta['path'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d41e1-d61e-4bc5-8e28-a5de9efbecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = [\n",
    "    (\n",
    "        \"3.9\", \n",
    "        \"Implementation of selected LCIA methods as described in https://v39.ecoquery.ecoinvent.org/File/File?fileName=ecoinvent+3.9+(2022)%2c+current%5csupporting+documents%5cecoinvent+3.9_LCIA_implementation.7z&hash=85940519&type=Files\"\n",
    "    ),\n",
    "    (\n",
    "        \"3.8\", \n",
    "        \"Implementation of selected LCIA methods as described in https://v39.ecoquery.ecoinvent.org/File/File?fileName=ecoinvent+3.8+(2021)%2c+outdated%5csupporting+documents%5cecoinvent+3.8_LCIA_implementation.7z&hash=1032948235&type=Files\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98affcf-9db7-42dc-8bfb-848629540ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version, description in CONFIG:\n",
    "    df = get_cleaned_dataframe(version)\n",
    "    resources, metadata = get_resources_and_metadata(df)\n",
    "    to_datapackage(\n",
    "        dirpath=Path.cwd() / \"outputs\" / version,\n",
    "        resources=resources,\n",
    "        resources_metadata=metadata,\n",
    "        name=f\"ecoinvent-{version}-lcia\",\n",
    "        author=\"Thomas Sonderegger\",\n",
    "        description=description,\n",
    "        elementary_flow_lists=[f\"ecoinvent-{version}\"],\n",
    "        version=\"1.0\",\n",
    "        licenses=[ECOINVENT_EULA_LICENSE],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
